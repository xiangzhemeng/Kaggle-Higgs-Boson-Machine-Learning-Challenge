{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "from cross_validation import *\n",
    "from tools import *\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "DATA_TEST_PATH = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training accuracy: 0.75853 - Test accuracy : 0.7551\n",
      "1: Training accuracy: 0.75843 - Test accuracy : 0.75974\n",
      "2: Training accuracy: 0.75819 - Test accuracy : 0.75912\n",
      "3: Training accuracy: 0.757445 - Test accuracy : 0.75656\n",
      "4: Training accuracy: 0.758455 - Test accuracy : 0.7594\n",
      "Average test accuracy: 0.7579839999999999\n",
      "Variance test accuracy: 3.344863999999969e-06\n"
     ]
    }
   ],
   "source": [
    "k_fold = 5\n",
    "gamma = 0.01\n",
    "max_iters = 500\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "list_accuracy_train = []\n",
    "list_accuracy_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    a_train, a_test = cross_validation(y, tX, k_indices, k, least_squares_gd, initial_w = None, max_iters = max_iters, gamma = gamma)\n",
    "    list_accuracy_train.append(a_train)\n",
    "    list_accuracy_test.append(a_test)\n",
    "\n",
    "for i in range(len(list_accuracy_train)):\n",
    "    print(\"{}: Training accuracy: {} - Test accuracy : {}\".format(i, list_accuracy_train[i], list_accuracy_test[i]))\n",
    "print(\"Average test accuracy: {}\".format(np.mean(list_accuracy_test)))\n",
    "print(\"Variance test accuracy: {}\".format(np.var(list_accuracy_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "gamma = 0.1\n",
    "max_iters = 500\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "list_accuracy_train = []\n",
    "list_accuracy_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    a_train, a_test = cross_validation(y, tX, k_indices, k, least_squares_sgd, initial_w = None, max_iters = max_iters, gamma = gamma)\n",
    "    list_accuracy_train.append(a_train)\n",
    "    list_accuracy_test.append(a_test)\n",
    "\n",
    "for i in range(len(list_accuracy_train)):\n",
    "    print(\"{}: Training accuracy: {} - Test accuracy : {}\".format(i, list_accuracy_train[i], list_accuracy_test[i]))\n",
    "print(\"Average test accuracy: {}\".format(np.mean(list_accuracy_test)))\n",
    "print(\"Variance test accuracy: {}\".format(np.var(list_accuracy_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training accuracy: 0.7753 - Test accuracy : 0.77166\n",
      "1: Training accuracy: 0.77587 - Test accuracy : 0.7757\n",
      "2: Training accuracy: 0.774895 - Test accuracy : 0.77594\n",
      "3: Training accuracy: 0.77425 - Test accuracy : 0.77394\n",
      "4: Training accuracy: 0.775435 - Test accuracy : 0.77788\n",
      "Average test accuracy: 0.7750239999999999\n",
      "Variance test accuracy: 4.388863999999989e-06\n"
     ]
    }
   ],
   "source": [
    "k_fold = 5\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "list_accuracy_train = []\n",
    "list_accuracy_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    a_train, a_test = cross_validation(y, tX, k_indices, k, least_squares)\n",
    "    list_accuracy_train.append(a_train)\n",
    "    list_accuracy_test.append(a_test)\n",
    "\n",
    "for i in range(len(list_accuracy_train)):\n",
    "    print(\"{}: Training accuracy: {} - Test accuracy : {}\".format(i, list_accuracy_train[i], list_accuracy_test[i]))\n",
    "print(\"Average test accuracy: {}\".format(np.mean(list_accuracy_test)))\n",
    "print(\"Variance test accuracy: {}\".format(np.var(list_accuracy_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training accuracy: 0.77417 - Test accuracy : 0.7711\n",
      "1: Training accuracy: 0.774735 - Test accuracy : 0.77464\n",
      "2: Training accuracy: 0.773785 - Test accuracy : 0.77516\n",
      "3: Training accuracy: 0.77315 - Test accuracy : 0.7722\n",
      "4: Training accuracy: 0.774415 - Test accuracy : 0.77638\n",
      "Average test accuracy: 0.7738959999999999\n",
      "Variance test accuracy: 3.8031039999999307e-06\n"
     ]
    }
   ],
   "source": [
    "#version without splitting dataset by jet\n",
    "k_fold = 5\n",
    "lambda_ = 0.002\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "list_accuracy_train = []\n",
    "list_accuracy_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    a_train, a_test = cross_validation(y, tX, k_indices, k, ridge_regression, lambda_ = lambda_)\n",
    "    list_accuracy_train.append(a_train)\n",
    "    list_accuracy_test.append(a_test)\n",
    "\n",
    "for i in range(len(list_accuracy_train)):\n",
    "    print(\"{}: Training accuracy: {} - Test accuracy : {}\".format(i, list_accuracy_train[i], list_accuracy_test[i]))\n",
    "print(\"Average test accuracy: {}\".format(np.mean(list_accuracy_test)))\n",
    "print(\"Variance test accuracy: {}\".format(np.var(list_accuracy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training accuracy: 0.83796 - Test accuracy : 0.834872\n",
      "1: Training accuracy: 0.838488 - Test accuracy : 0.834992\n",
      "Average test accuracy: 0.834932\n",
      "Variance test accuracy: 3.6000000000005393e-09\n"
     ]
    }
   ],
   "source": [
    "#version with splitting dataset by jet\n",
    "k_fold = 2\n",
    "lambdas = [0.002, 0.001, 0.001]\n",
    "degrees = [4, 7 ,9]\n",
    "\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "list_accuracy_train = []\n",
    "list_accuracy_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    accuracy_train, accuracy_test = cross_validation_ridge_regression(y, tX, k_indices, k, lambdas, degrees)\n",
    "    list_accuracy_train.append(accuracy_train)\n",
    "    list_accuracy_test.append(accuracy_test)\n",
    "\n",
    "for i in range(len(list_accuracy_train)):\n",
    "    print(\"{}: Training accuracy: {} - Test accuracy : {}\".format(i, list_accuracy_train[i], list_accuracy_test[i]))\n",
    "print(\"Average test accuracy: {}\".format(np.mean(list_accuracy_test)))\n",
    "print(\"Variance test accuracy: {}\".format(np.var(list_accuracy_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run.py code --> ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "\n",
      "Start generating prediction files...\n",
      "\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...\\n')\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tx_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "\n",
    "lambdas = [0.002, 0.001, 0.001]\n",
    "degrees = [4, 7, 9]\n",
    "\n",
    "y_pred = np.zeros(tx_test.shape[0])\n",
    "\n",
    "dict_jets_train = group_features_by_jet(tx_train)\n",
    "dict_jets_test = group_features_by_jet(tx_test)\n",
    "\n",
    "for index in range(len(dict_jets_train)):\n",
    "    x_train = tx_train[dict_jets_train[index]]\n",
    "    x_test = tx_test[dict_jets_test[index]]\n",
    "    y_train = y[dict_jets_train[index]]\n",
    "\n",
    "    #data processing\n",
    "    x_train, x_test = process_data(x_train, x_test)\n",
    "    x_train = build_polynomial_features(x_train, degrees[index])\n",
    "    x_test = build_polynomial_features(x_test, degrees[index])\n",
    "    x_train = np.hstack((np.ones((x_train.shape[0], 1)), x_train))\n",
    "    x_test = np.hstack((np.ones((x_test.shape[0], 1)), x_test))\n",
    "\n",
    "    weight, loss_train = ridge_regression(y_train, x_train, lambdas[index])\n",
    "\n",
    "    temp_test_pred = predict_labels(weight, x_test)\n",
    "\n",
    "    y_pred[dict_jets_test[index]] = temp_test_pred\n",
    "    \n",
    "print('Start generating prediction files...\\n')\n",
    "OUTPUT_PATH = 'data/output_ridge_regression3.csv'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "\n",
    "print('Finish!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training accuracy: 0.725848 - Test accuracy : 0.726168\n",
      "1: Training accuracy: 0.727192 - Test accuracy : 0.726472\n",
      "Average test accuracy: 0.7263200000000001\n",
      "Variance test accuracy: 2.3103999999995586e-08\n"
     ]
    }
   ],
   "source": [
    "k_fold = 2\n",
    "gamma = 0.01\n",
    "max_iters = 1000\n",
    "\n",
    "# Split data in k-fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "list_accuracy_train = []\n",
    "list_accuracy_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    a_train, a_test = cross_validation(y, tX, k_indices, k, logistic_regression, initial_w = None ,max_iters = max_iters, gamma = gamma)\n",
    "    list_accuracy_train.append(a_train)\n",
    "    list_accuracy_test.append(a_test)\n",
    "\n",
    "for i in range(len(list_accuracy_train)):\n",
    "    print(\"{}: Training accuracy: {} - Test accuracy : {}\".format(i, list_accuracy_train[i], list_accuracy_test[i]))\n",
    "print(\"Average test accuracy: {}\".format(np.mean(list_accuracy_test)))\n",
    "print(\"Variance test accuracy: {}\".format(np.var(list_accuracy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
